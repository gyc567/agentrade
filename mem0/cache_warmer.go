package mem0

import (
	"context"
	"log"
	"strings"
	"sync"
	"time"

	lru "github.com/hashicorp/golang-lru/v2"
)

// CacheWarmer P0ä¿®å¤: ç½‘ç»œå»¶è¿Ÿé¢„çƒ­æœºåˆ¶
// ä½œç”¨: åœ¨å†³ç­–å‰5åˆ†é’Ÿå¼‚æ­¥é¢„æŸ¥è¯¢,ç»“æœè¿›ç¼“å­˜
// æ”¶ç›Š: P95å»¶è¿Ÿä» 2.5ç§’ â†’ <500ms
type CacheWarmer struct {
	store        MemoryStore
	cache        *lru.Cache[string, CacheEntry]
	interval     time.Duration
	cacheTTL     time.Duration
	mu           sync.RWMutex
	ticker       *time.Ticker
	done         chan struct{}
	warmupQueries []WarmupQuery
	metrics      *CacheMetrics
}

// CacheEntry ç¼“å­˜æ¡ç›®
type CacheEntry struct {
	Data      interface{}
	Timestamp time.Time
	HitCount  int64
}

// WarmupQuery é¢„çƒ­æŸ¥è¯¢å®šä¹‰
type WarmupQuery struct {
	Name     string
	QueryFn  func(ctx context.Context) (interface{}, error)
	Priority int // 1-10, 10æœ€é«˜
}

// CacheMetrics ç¼“å­˜æŒ‡æ ‡
type CacheMetrics struct {
	Hits          int64
	Misses        int64
	Evictions     int64
	LastUpdateAt  time.Time
	mu            sync.RWMutex
}

// NewCacheWarmer åˆ›å»ºç¼“å­˜é¢„çƒ­å™¨
func NewCacheWarmer(store MemoryStore, interval time.Duration, cacheTTL time.Duration) *CacheWarmer {
	cache, _ := lru.New[string, CacheEntry](1000) // æœ€å¤š1000æ¡è®°å½•

	warmer := &CacheWarmer{
		store:    store,
		cache:    cache,
		interval: interval,
		cacheTTL: cacheTTL,
		done:     make(chan struct{}),
		metrics:  &CacheMetrics{},
	}

	// å®šä¹‰é¢„çƒ­æŸ¥è¯¢
	warmer.defineWarmupQueries()

	return warmer
}

// defineWarmupQueries å®šä¹‰é¢„çƒ­æŸ¥è¯¢åˆ—è¡¨
func (w *CacheWarmer) defineWarmupQueries() {
	w.warmupQueries = []WarmupQuery{
		{
			Name:     "similar_trades",
			Priority: 10,
			QueryFn: func(ctx context.Context) (interface{}, error) {
				// æŸ¥è¯¢æœ€è¿‘çš„ç›¸ä¼¼äº¤æ˜“
				query := Query{
					Type:       "semantic_search",
					Limit:      5,
					Similarity: 0.7,
				}
				return w.store.Search(ctx, query)
			},
		},
		{
			Name:     "failure_patterns",
			Priority: 9,
			QueryFn: func(ctx context.Context) (interface{}, error) {
				// æŸ¥è¯¢å¤±è´¥æ¨¡å¼
				query := Query{
					Type: "graph_query",
					Filters: []QueryFilter{
						{Field: "type", Operator: "eq", Value: "reflection"},
						{Field: "severity", Operator: "in", Value: []string{"high", "critical"}},
					},
					Limit: 3,
				}
				return w.store.Search(ctx, query)
			},
		},
		{
			Name:     "successful_parameters",
			Priority: 8,
			QueryFn: func(ctx context.Context) (interface{}, error) {
				// æŸ¥è¯¢æˆåŠŸçš„å‚æ•°
				query := Query{
					Type: "direct_lookup",
					Filters: []QueryFilter{
						{Field: "type", Operator: "eq", Value: "outcome"},
						{Field: "status", Operator: "eq", Value: "evaluated"},
					},
					Limit: 3,
				}
				return w.store.Search(ctx, query)
			},
		},
		{
			Name:     "memory_stats",
			Priority: 7,
			QueryFn: func(ctx context.Context) (interface{}, error) {
				// æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
				return w.store.GetStats(ctx)
			},
		},
	}
}

// Start å¯åŠ¨ç¼“å­˜é¢„çƒ­
func (w *CacheWarmer) Start(ctx context.Context) {
	log.Println("ğŸ”„ CacheWarmerå¯åŠ¨ä¸­...")

	// ç«‹å³æ‰§è¡Œä¸€æ¬¡é¢„çƒ­
	w.warmup(ctx)

	// å®šæœŸæ‰§è¡Œé¢„çƒ­
	w.ticker = time.NewTicker(w.interval)
	defer w.ticker.Stop()

	go func() {
		for {
			select {
			case <-ctx.Done():
				log.Println("ğŸ›‘ CacheWarmerå·²åœæ­¢")
				return
			case <-w.done:
				log.Println("ğŸ›‘ CacheWarmerå·²åœæ­¢")
				return
			case <-w.ticker.C:
				w.warmup(ctx)
			}
		}
	}()
}

// Stop åœæ­¢ç¼“å­˜é¢„çƒ­
func (w *CacheWarmer) Stop() {
	select {
	case w.done <- struct{}{}:
	default:
	}
}

// warmup æ‰§è¡Œé¢„çƒ­æŸ¥è¯¢
func (w *CacheWarmer) warmup(ctx context.Context) {
	startTime := time.Now()
	log.Printf("ğŸ”¥ å¼€å§‹ç¼“å­˜é¢„çƒ­ (æ—¶é—´: %s)", startTime.Format("15:04:05"))

	// åˆ›å»ºè¶…æ—¶context
	warmupCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
	defer cancel()

	// å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰é¢„çƒ­æŸ¥è¯¢
	var wg sync.WaitGroup
	successCount := 0
	failureCount := 0

	for _, query := range w.warmupQueries {
		wg.Add(1)
		go func(q WarmupQuery) {
			defer wg.Done()

			cacheKey := "warmup_" + q.Name
			result, err := q.QueryFn(warmupCtx)

			if err != nil {
				log.Printf("  âš ï¸  é¢„çƒ­æŸ¥è¯¢å¤±è´¥ (%s): %v", q.Name, err)
				failureCount++
				return
			}

			// ä¿å­˜åˆ°ç¼“å­˜
			w.mu.Lock()
			w.cache.Add(cacheKey, CacheEntry{
				Data:      result,
				Timestamp: time.Now(),
			})
			w.mu.Unlock()

			successCount++
			log.Printf("  âœ… é¢„çƒ­æŸ¥è¯¢æˆåŠŸ (%s)", q.Name)
		}(query)
	}

	wg.Wait()

	duration := time.Since(startTime)
	log.Printf("âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ (è€—æ—¶: %.0fms, æˆåŠŸ: %d, å¤±è´¥: %d)", duration.Seconds()*1000, successCount, failureCount)

	// æ›´æ–°æŒ‡æ ‡
	w.metrics.mu.Lock()
	w.metrics.LastUpdateAt = time.Now()
	w.metrics.mu.Unlock()
}

// Get è·å–ç¼“å­˜æ•°æ®
func (w *CacheWarmer) Get(key string) (interface{}, bool) {
	w.mu.RLock()
	entry, found := w.cache.Get(key)
	w.mu.RUnlock()

	if !found {
		w.metrics.mu.Lock()
		w.metrics.Misses++
		w.metrics.mu.Unlock()
		return nil, false
	}

	// æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
	if time.Since(entry.Timestamp) > w.cacheTTL {
		w.mu.Lock()
		w.cache.Remove(key)
		w.mu.Unlock()

		w.metrics.mu.Lock()
		w.metrics.Misses++
		w.metrics.mu.Unlock()
		return nil, false
	}

	// æ›´æ–°å‘½ä¸­æ¬¡æ•°
	entry.HitCount++
	w.mu.Lock()
	w.cache.Add(key, entry)
	w.mu.Unlock()

	w.metrics.mu.Lock()
	w.metrics.Hits++
	w.metrics.mu.Unlock()

	return entry.Data, true
}

// Set æ‰‹åŠ¨è®¾ç½®ç¼“å­˜
func (w *CacheWarmer) Set(key string, data interface{}) {
	w.mu.Lock()
	w.cache.Add(key, CacheEntry{
		Data:      data,
		Timestamp: time.Now(),
	})
	w.mu.Unlock()
}

// Clear æ¸…ç©ºç¼“å­˜
func (w *CacheWarmer) Clear() {
	w.mu.Lock()
	w.cache.Purge()
	w.mu.Unlock()
	log.Println("âœ… ç¼“å­˜å·²æ¸…ç©º")
}

// GetMetrics è·å–ç¼“å­˜æŒ‡æ ‡
func (w *CacheWarmer) GetMetrics() CacheMetrics {
	w.metrics.mu.RLock()
	defer w.metrics.mu.RUnlock()

	// è¿”å›ä¸åŒ…å«é”çš„å‰¯æœ¬
	return CacheMetrics{
		Hits:         w.metrics.Hits,
		Misses:       w.metrics.Misses,
		Evictions:    int64(1000 - w.cache.Len()), // LRUå¤§å°å‡å»å½“å‰é¡¹æ•°
		LastUpdateAt: w.metrics.LastUpdateAt,
	}
}

// GetHitRate è·å–å‘½ä¸­ç‡
func (w *CacheWarmer) GetHitRate() float64 {
	w.metrics.mu.RLock()
	defer w.metrics.mu.RUnlock()

	total := w.metrics.Hits + w.metrics.Misses
	if total == 0 {
		return 0.0
	}

	return float64(w.metrics.Hits) / float64(total) * 100
}

// PrintStats æ‰“å°ç»Ÿè®¡ä¿¡æ¯
func (w *CacheWarmer) PrintStats() {
	metrics := w.GetMetrics()
	hitRate := w.GetHitRate()

	w.mu.RLock()
	cacheSize := w.cache.Len()
	w.mu.RUnlock()

	log.Println("\nğŸ“Š ç¼“å­˜é¢„çƒ­ç»Ÿè®¡:")
	log.Println(strings.Repeat("â•", 50))
	log.Printf("  å‘½ä¸­: %d | æœªå‘½ä¸­: %d | å‘½ä¸­ç‡: %.1f%%\n", metrics.Hits, metrics.Misses, hitRate)
	log.Printf("  ç¼“å­˜å¤§å°: %dæ¡ | æœ€å¤§: 1000æ¡\n", cacheSize)
	log.Printf("  é©±é€: %d | æœ€åæ›´æ–°: %s\n", metrics.Evictions, metrics.LastUpdateAt.Format("15:04:05"))
	log.Println(strings.Repeat("â•", 50))
}
